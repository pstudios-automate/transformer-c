=== Project Overview Report ===
Thu Oct 23 12:46:30 PM EDT 2025

------------------------------------------------------------
ðŸ“„ File: ./activation_functions.c
------------------------------------------------------------

    #include <math.h>
    #include <stdio.h>


    ðŸ”¹ double sigmoid(double x)
    ðŸ”¹ double leaky_relu(double x, double alpha)
    ðŸ”¹ double swish(double x)


------------------------------------------------------------
ðŸ“„ File: ./activation_functions.h
------------------------------------------------------------





------------------------------------------------------------
ðŸ“„ File: ./backpropagation.c
------------------------------------------------------------

    #include <math.h>
    #include <stdio.h>


    ðŸ”¹ double calculate_mse(double output_array[], double expected_output_array[], int size)
    ðŸ”¹ double clip_gradient_backpropagation(double gradient, double clip_threshold)
    ðŸ”¹ void update_weights_last_layer(double loss, double learning_rate, double final_layer_weights[], double semi_final_layer_weights[], int final_layer_size, int semi_final_layer_size, double clip_threshold)
    ðŸ”¹ void update_semi_final_layer_weights(double loss, double learning_rate, double semi_final_layer_weights[], int semi_final_layer_size, double clip_threshold)


------------------------------------------------------------
ðŸ“„ File: ./backpropagation.h
------------------------------------------------------------

    #include <math.h>  




------------------------------------------------------------
ðŸ“„ File: ./Data_Loading_Cleaning.c
------------------------------------------------------------

    #include <stdio.h>
    #include <stdlib.h> // FOR MEMORY ALLOCATION
    #include <string.h> // FOR STRING HANDLING FUNCTIONS
    #include <ctype.h>  // FOR CHARACTER HANDLING FUNCTIONS (E.G. , TOLOWER )


    ðŸ”¹ char* readFileToString(const char *filename)
    ðŸ”¹ char** SplitSentences( char *raw_text )
    ðŸ”¹ char* Cleaned_Text(char *raw_text)


------------------------------------------------------------
ðŸ“„ File: ./Data_Loading_Cleaning.h
------------------------------------------------------------

    #include <stdio.h>
    #include <stdlib.h>
    #include <string.h>
    #include <ctype.h>




------------------------------------------------------------
ðŸ“„ File: ./Data_Preprocessing.c
------------------------------------------------------------

    #include "Data_Preprocessing.h"
    #include <stdlib.h>  // FOR MALLOC AND FREE
    #include <stdio.h>
    #include <math.h>    // FOR SQRT


    ðŸ”¹ void scale_matrix(float matrix[ EMBEDDING_SIZE][MATRIX_SIZE])
    ðŸ”¹ void min_max_normalize_and_scale(float* data, size_t size, float new_min, float new_max)
    ðŸ”¹ size_t get_meaningful_length(const float* data, size_t size)
    ðŸ”¹ void Add_Positional_Encoding(float embedding_matrix[][2], int max_sentence_length)


------------------------------------------------------------
ðŸ“„ File: ./Data_Preprocessing.h
------------------------------------------------------------

    #include <stddef.h>  // FOR SIZE_T
    #include <float.h> // For FLT_MAX




------------------------------------------------------------
ðŸ“„ File: ./feed_forward_layer.c
------------------------------------------------------------

    #include <stdio.h>
    #include <stdlib.h>


    ðŸ”¹ void read_weights(const char* path, double* semi_final_layer_weights, int num_weights)


------------------------------------------------------------
ðŸ“„ File: ./feed_forward_layer.h
------------------------------------------------------------

    #include <stdio.h>




------------------------------------------------------------
ðŸ“„ File: ./main.c
------------------------------------------------------------

    #include <stdio.h>
    #include <math.h>
    #include <unistd.h>
    #include <omp.h>
    #include "Data_Loading_Cleaning.h"
    #include "Tokenizer.h"
    #include "Data_Preprocessing.h"
    #include "transformer_block.h"
    #include "feed_forward_layer.h"
    #include "activation_functions.h"
    #include "backpropagation.h"


    ðŸ”¹ int main()


------------------------------------------------------------
ðŸ“„ File: ./self_attention_layer.c
------------------------------------------------------------

    #include <stdio.h>
    #include <stdlib.h>
    #include <math.h>


    ðŸ”¹ float dot_product(float *a, float *b, int dim)
    ðŸ”¹ void softmax(float *input, float *output, int length)
    ðŸ”¹ void initialize_embedding(float embedding[VOCAB_SIZE][EMBEDDING_DIM])
    ðŸ”¹ void generate_positional_encoding(float positional_encoding[VOCAB_SIZE][EMBEDDING_DIM])
    ðŸ”¹ void lookup_embedding(float embedding[VOCAB_SIZE][EMBEDDING_DIM], int token_index, float *output)
    ðŸ”¹ void initialize_weight_matrix(float *weight, int rows, int cols)
    ðŸ”¹ int main()


------------------------------------------------------------
ðŸ“„ File: ./test.c
------------------------------------------------------------

    #include <stdio.h>
    #include <stdlib.h>
    #include <limits.h>


    ðŸ”¹ void scale_matrix(double matrix[MATRIX_SIZE][MATRIX_SIZE])
    ðŸ”¹ void print_matrix(double matrix[MATRIX_SIZE][MATRIX_SIZE])
    ðŸ”¹ int main()


------------------------------------------------------------
ðŸ“„ File: ./Tokenizer.c
------------------------------------------------------------

    #include <stdio.h>
    #include <stdlib.h> // FOR MEMORY ALLOCATION, rand() and RAND_MAX
    #include <string.h> // FOR STRING HANDLING FUNCTIONS
    #include <ctype.h>  // FOR CHARACTER HANDLING FUNCTIONS (E.G. , TOLOWER )
    #include <math.h>     // FOR sin() AND cos()

    typedef struct word_token_node {
        struct word_token_node *next; // POINTER TO THE NEXT NODE IN THE LINKED LIST

    ðŸ”¹ unsigned int hash(const char* word)
    ðŸ”¹ void insertWord(const char* word)
    ðŸ”¹ int isWordPresent(const char* word)
    ðŸ”¹ void Print_Tokens_And_Ids()
    ðŸ”¹ unsigned int getTokenId(const char* word)
    ðŸ”¹ float generate_random()
    ðŸ”¹ float** Word_Embedding_Generation(int token_id)
    ðŸ”¹ void extractUniqueWords(char** sentences)
    ðŸ”¹ void getEmbeddingByTokenId(unsigned int token_id, double expected_embedding[2])


------------------------------------------------------------
ðŸ“„ File: ./Tokenizer.h
------------------------------------------------------------

    #include <stdio.h>
    #include <stdlib.h>
    #include <string.h>
    #include <ctype.h>

    typedef struct word_token_node {
        struct word_token_node *next;



------------------------------------------------------------
ðŸ“„ File: ./transformer_block.c
------------------------------------------------------------

    #include "transformer_block.h"
    #include <math.h>
    #include <stdlib.h>
    #include <stdio.h>


    ðŸ”¹ double* positional_encoding( int index, int vector_size )
    ðŸ”¹ double read_single_value_from_file(const char* filename)
    ðŸ”¹ void initialize_matrices_from_files()
    ðŸ”¹ void print_matrix(const char* name, double matrix[MATRIX_SIZE][MATRIX_SIZE])
    ðŸ”¹ void dot_product(double A[MATRIX_SIZE][MATRIX_SIZE], double B[MATRIX_SIZE][MATRIX_SIZE], double result[MATRIX_SIZE][MATRIX_SIZE])
    ðŸ”¹ void transpose(double matrix[MATRIX_SIZE][MATRIX_SIZE], double transposed[MATRIX_SIZE][MATRIX_SIZE])
    ðŸ”¹ void softmax(double matrix[MATRIX_SIZE][MATRIX_SIZE])
    ðŸ”¹ void calculate_attention(double Q[MATRIX_SIZE][MATRIX_SIZE], double K[MATRIX_SIZE][MATRIX_SIZE], double V[MATRIX_SIZE][MATRIX_SIZE], double result[MATRIX_SIZE][MATRIX_SIZE])
    ðŸ”¹ void matrix_multiply(double A[][MATRIX_SIZE], double B[][MATRIX_SIZE], double result[][MATRIX_SIZE], int rowsA, int colsA, int colsB)
    ðŸ”¹ void apply_softmax(double matrix[][MATRIX_SIZE], int rows, int cols)
    ðŸ”¹ double clip_gradient_transformer(double gradient)
    ðŸ”¹ void compute_self_attention(float embedding_matrix[][MATRIX_SIZE], double k_matrix[][MATRIX_SIZE], double q_matrix[][MATRIX_SIZE], double v_matrix[][MATRIX_SIZE], int length, double self_attention_matrix[][MATRIX_SIZE])
    ðŸ”¹ void add_matrices(float matrix1[][MATRIX_SIZE], double matrix2[][MATRIX_SIZE], double result_matrix[][MATRIX_SIZE], int rows, int cols)
    ðŸ”¹ void update_attention_matrices(double loss, double learning_rate)


------------------------------------------------------------
ðŸ“„ File: ./transformer_block.h
------------------------------------------------------------

    #include <math.h>
    #include <stdlib.h>




============================================================
ðŸ“Š SUMMARY
============================================================
Total files: 17
Total functions: 0

